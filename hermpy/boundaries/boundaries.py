import datetime as dt
import os

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

from hermpy.utils import Constants


def Load_Crossings(path: str, backend: str = "Philpott", include_data_gaps=True) -> pd.DataFrame:
    """Loads a pandas DataFrame from

    Parameters
    ----------
    path : str
        An abosolute path to a crossing intervals file

    backend : str {"Philpott", "Sun" (to be added)}, optional
        Which list is being loaded. Informs which backend function
        to use. Backend must match file being loaded.

    include_data_gaps : bool {True, False}, optional
        Should data gaps be included in the list.


    Returns
    -------
    Crossings Data : pandas.DataFrame
    """

    if backend == "Philpott":
        crossings = Reformat_Philpott(path, include_data_gaps=include_data_gaps)

    else:
        raise ValueError(f"Unknown backend: {backend}, options are (philpott, sun)")

    # Flatten multi-index
    crossings.columns = [" ".join(col).strip() for col in crossings.columns.values]

    return crossings


def Plot_Crossing_Intervals(
    ax: plt.Axes,
    start: dt.datetime,
    end: dt.datetime,
    crossings: pd.DataFrame,
    label: bool = True,
    height: float = 0.9,
    color: str = "orange",
    lw: float = 1,
) -> None:
    """Adds vertical lines marking the start and end of given
    crossing intervals.

    Detects crossing intervals present in range of data.
    Vertical lines in the form of pyplot.axvlines() are added
    to a pyplot.Axes object `ax`, with optional labelling of
    type.

    Parameters
    ---------
    ax : pyplot.Axes
        The pyplot axis to add the vertical lines to.

    start : datetime.datetime
        The starting point of the data plotted.

    end : datetime.datetime
        The ending point of the data plotted.

    crossings : pandas.DataFrame
        A pandas DataFrame with crossings data, as generated by
        Load_Crossings().

    label : bool {`True`, `False`}
        If `True`, adds a label specificing the boundary type.

    color : str {`orange`, any other matplotlib named colour}


    Returns
    -------
    None
    """

    for _, row in crossings.iterrows():

        # If crossing interval is in plot
        if (row["Start Time"] > start and row["Start Time"] < end) or (
            row["End Time"] > start and row["End Time"] < end
        ):
            midpoint = row["Start Time"] + (row["End Time"] - row["Start Time"]) / 2

            if label:
                ax.text(
                    midpoint,
                    height,
                    row["Type"].upper().replace("_", " "),
                    transform=ax.get_xaxis_transform(),
                    color=color,
                    ha="center",
                    va="center",
                )

            ax.axvline(row["Start Time"], color=color, ls="dashed", lw=lw)
            ax.axvline(row["End Time"], color=color, ls="dashed", lw=lw)


def Plot_Crossings_As_Minutes_Before(
    ax: plt.Axes,
    crossings: pd.DataFrame,
    data_start: dt.datetime,
    data_end: dt.datetime,
    apoapsis_time: dt.datetime,
    label: bool = True,
    height: float = 0.9,
    color: str = "orange",
    show_partial_crossings=True,
) -> None:
    """
    Plots crossings as vlines with respect to the closest
    apoapsis.

    Detects crossing intervals present in range of data.
    Vertical lines in the form of pyplot.axvlines() are added
    to a pyplot.Axes object `ax`, with optional labelling of
    type. A reference `apoapsis_time` is used to convert to
    minutes before apoapsis instead of a date.

    Parameters
    ---------
    ax : pyplot.Axes
        The pyplot axis to add the vertical lines to.

    crossings : pandas.DataFrame
        A pandas DataFrame with crossings data, as generated by
        Load_Crossings().

    data_start : datetime.datetime
        The starting point of the data plotted.

    data_end : datetime.datetime
        The ending point of the data plotted.

    apoapsis_time : datetime.datetime
        The time of the reference apoapsis.

    label : bool {`True`, `False`}
        If `True`, adds a label specificing the boundary type.

    height : float {`0.9`}, optional
        The height of the label in axis units.

    color : str {`orange`, any other matplotlib named colour}, optional
        The colour of the vertical lines and labels.


    Returns
    -------
    None
    """

    for _, row in crossings.iterrows():

        # Check if crossing interval is in plot
        if (row["Start Time"] > data_start and row["Start Time"] < data_end) or (
            row["End Time"] > data_start and row["End Time"] < data_end
        ):

            if not show_partial_crossings:
                if not (
                    row["Start Time"] > data_start and row["Start Time"] < data_end
                ) and (row["End Time"] > data_start and row["End Time"] < data_end):
                    continue

            midpoint = row["Start Time"] + (row["End Time"] - row["Start Time"]) / 2

            # Convert times into minutes before apoapsis
            start_minutes = (apoapsis_time - row["Start Time"]).total_seconds() / 60
            end_minutes = (apoapsis_time - row["End Time"]).total_seconds() / 60

            if label:
                ax.text(
                    (midpoint - data_start).total_seconds()
                    / (data_end - data_start).total_seconds(),
                    height,
                    row["Type"].upper().replace("_", " "),
                    transform=ax.transAxes,
                    color=color,
                    ha="center",
                    va="center",
                )

            ax.axvline(start_minutes, color=color, ls="dashed")
            ax.axvline(end_minutes, color=color, ls="dashed")


def Get_Crossings_As_Points(
    crossings: pd.DataFrame, start: dt.datetime, end: dt.datetime
) -> list[list[float]]:
    """Get boundary crossing positions as data points.

    Takes a crossing list input along with a start and stop datetime
    and outputs the positions of any crossings.


    Parameters
    ----------
    crossings : pandas.DataFrame
        A pandas DataFrame with crossings data, as generated by
        Load_Crossings().

    start : datetime.datetime
        The starting point of the search

    end : datetime.datetime
        The ending point of the search


    Returns
    -------
    positions : list[ list[ float ] ]
        A list of positions where boundaries were crossed in that time.
    """

    positions = []

    for _, row in crossings.iterrows():

        # Check if crossing interval is in plot
        if (row["start"] > start and row["start"] < end) or (
            row["end"] > start and row["end"] < end
        ):

            # Get position of midpoint
            midpoint_x_msm = (row["start_x_msm"] + row["end_x_msm"]) / 2
            midpoint_y_msm = (row["start_y_msm"] + row["end_y_msm"]) / 2
            midpoint_z_msm = (row["start_z_msm"] + row["end_z_msm"]) / 2
            position = [midpoint_x_msm, midpoint_y_msm, midpoint_z_msm]

            positions.append(position)

    return positions


def Reformat_Sun(input_directory: str) -> pd.DataFrame:
    """Reads directory containing Sun 2023 crossing lists and reformats to
    a singular pandas dataframe.

    https://zenodo.org/records/8298647

    Parameters
    ----------
    input_directory : str
        Path to a directory containing the files from the zenodo data set.


    Returns
    -------
    out : pandas.DataFrame
    """

    # Process:
    # Load and loop through each file in the directory.
    # Extract and form a dataframe from the information in the file
    # Concatanate all dataframes and then sort by start time.

    sub_crossings_lists = []

    # First load each file in the directory
    for path in [
        input_directory + file_name for file_name in os.listdir(input_directory)
    ]:

        file_data_numeric = np.genfromtxt(path, dtype=float, usecols=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
        file_data_letters = np.genfromtxt(path, dtype=str, usecols=(12, 13))

        start_year = file_data_numeric[:, 0].astype(int)
        start_month = file_data_numeric[:, 1].astype(int)
        start_day = file_data_numeric[:, 2].astype(int)
        start_hour = file_data_numeric[:, 3].astype(int)
        start_minute = file_data_numeric[:, 4].astype(int)
        start_second = abs(
            file_data_numeric[:, 5]
        )  # ABOSULTE VALUE IS NEEDED AS THERE ARE NEGATIVE??? SECONDS

        start_times = []

        for y, m, d, H, M, S, us in zip(
            start_year,
            start_month,
            start_day,
            start_hour,
            start_minute,
            np.floor(start_second).astype(int),
            ((start_second - np.floor(start_second)) * 1e6).astype(
                int
            ),  # convert decimal seconds to microseconds
        ):

            start_times.append(
                dt.datetime(y, m, d)
                + dt.timedelta(
                    hours=float(H),
                    minutes=float(M),
                    seconds=float(S),
                    microseconds=float(us),
                )
            )

        end_year = file_data_numeric[:, 6].astype(int)
        end_month = file_data_numeric[:, 7].astype(int)
        end_day = file_data_numeric[:, 8].astype(int)
        end_hour = file_data_numeric[:, 9].astype(int)
        end_minute = file_data_numeric[:, 10].astype(int)
        end_second = abs(
            file_data_numeric[:, 11]
        )  # ABOSULTE VALUE IS NEEDED AS THERE ARE NEGATIVE??? SECONDS

        end_times = []

        for y, m, d, H, M, S, us in zip(
            end_year,
            end_month,
            end_day,
            end_hour,
            end_minute,
            np.floor(end_second).astype(int),
            ((end_second - np.floor(end_second)) * 1e6).astype(
                int
            ),  # convert decimal seconds to microseconds
        ):

            end_times.append(
                dt.datetime(y, m, d)
                + dt.timedelta(
                    hours=float(H),
                    minutes=float(M),
                    seconds=float(S),
                    microseconds=float(us),
                )
            )

        boundary_id = file_data_letters[:, 0][0]
        match boundary_id:

            case "BSI":
                new_boundary_id = "BS_IN"

            case "BSO":
                new_boundary_id = "BS_OUT"

            case "MPI":
                new_boundary_id = "MP_IN"

            case "MPO":
                new_boundary_id = "MP_OUT"

            case _:
                raise Exception(f"Unrecognised boundary id ({boundary_id}) in {path}")

        boundary_ids = [new_boundary_id for _ in range(len(file_data_numeric))]

        sub_crossings_list = pd.DataFrame(
            {
                "start": start_times,
                "end": end_times,
                "type": boundary_ids,
            }
        )

        sub_crossings_lists.append(sub_crossings_list)

    full_list = pd.concat(sub_crossings_lists)

    full_list.sort_values("start", inplace=True)
    full_list.reset_index(drop=True, inplace=True)

    # Now that we have the full list, we can add on the extra columns we need!


def Reformat_Philpott(input_path: str, include_data_gaps=True) -> pd.DataFrame:
    """Takes Philpott list from suplimetary information and reformats

    Backend function, developer use only

    Parameters
    ----------
    input_path : str
        Path to Philpott+ (2020) table S1

    include_data_gaps : bool {True, False}, optional
        Should data gaps be included in the list.


    Returns
    -------
    out : pandas.DataFrame
    """

    philpott_csv = pd.read_excel(input_path)

    types = []

    start_times = []
    end_times = []

    start_x_mso_radii = []
    start_y_mso_radii = []
    start_z_mso_radii = []

    end_x_mso_radii = []
    end_y_mso_radii = []
    end_z_mso_radii = []

    start_x_mso_km = []
    start_y_mso_km = []
    start_z_mso_km = []

    end_x_mso_km = []
    end_y_mso_km = []
    end_z_mso_km = []

    for i, row in philpott_csv.iterrows():
        assert type(i) == int

        # We loop through each row, if the row type is equal to
        # an odd number, it is the start edge of the interval. The
        # following type will be even, and the end edge of the
        # interval.

        if row["Boundary number"] % 2 != 0:

            match row["Boundary number"]:
                case 1:
                    types.append("BS_IN")

                case 3:
                    types.append("MP_IN")

                case 5:
                    types.append("MP_OUT")

                case 7:
                    types.append("BS_OUT")

                # 9 and 10 represent data gaps
                case 9:
                    types.append("DATA_GAP")

                case _:
                    raise ValueError(f"Unrecognised boundary number in Philpott list: {row['Boundary number']}")

            start_string = f"{row['Year']}{row['Day of year']}{row['Hour']}{row['Minute']}{row['Second']}"
            start_time = dt.datetime.strptime(start_string, "%Y.0%j.0%H.0%M.0%S.%f")
            start_times.append(start_time)

            start_x_mso_radii.append(row["X_MSO (km)"] / Constants.MERCURY_RADIUS_KM)
            start_y_mso_radii.append(row["Y_MSO (km)"] / Constants.MERCURY_RADIUS_KM)
            start_z_mso_radii.append(row["Z_MSO (km)"] / Constants.MERCURY_RADIUS_KM)

            start_x_mso_km.append(row["X_MSO (km)"])
            start_y_mso_km.append(row["Y_MSO (km)"])
            start_z_mso_km.append(row["Z_MSO (km)"])


            next_row = philpott_csv.iloc[i + 1]
            # Next row boundary number should always be even
            # Next row boundary number should always follow that of the current row
            assert next_row["Boundary number"] % 2 == 0
            assert next_row["Boundary number"] == row["Boundary number"] + 1

            end_string = f"{next_row['Year']}{next_row['Day of year']}{next_row['Hour']}{next_row['Minute']}{next_row['Second']}"
            end_time = dt.datetime.strptime(end_string, "%Y.0%j.0%H.0%M.0%S.%f")
            end_times.append(end_time)

            end_x_mso_radii.append(next_row["X_MSO (km)"] / Constants.MERCURY_RADIUS_KM)
            end_y_mso_radii.append(next_row["Y_MSO (km)"] / Constants.MERCURY_RADIUS_KM)
            end_z_mso_radii.append(next_row["Z_MSO (km)"] / Constants.MERCURY_RADIUS_KM)

            end_x_mso_km.append(next_row["X_MSO (km)"])
            end_y_mso_km.append(next_row["Y_MSO (km)"])
            end_z_mso_km.append(next_row["Z_MSO (km)"])

    # Format this as a dictionary
    list_data = {
        "Interval Type": types,
        "Interval Start": start_times,
        "Interval End": end_times,

        "X MSO Start (radii)": start_x_mso_radii,
        "Y MSO Start (radii)": start_y_mso_radii,
        "Z MSO Start (radii)": start_z_mso_radii,

        "X MSO End (radii)": end_x_mso_radii,
        "Y MSO End (radii)": end_y_mso_radii,
        "Z MSO End (radii)": end_z_mso_radii,

        "X MSO Start (km)": start_x_mso_km,
        "Y MSO Start (km)": start_y_mso_km,
        "Z MSO Start (km)": start_z_mso_km,

        "X MSO End (km)": end_x_mso_km,
        "Y MSO End (km)": end_y_mso_km,
        "Z MSO End (km)": end_z_mso_km,

        "X MSM Start (radii)": start_x_mso_radii,
        "Y MSM Start (radii)": start_y_mso_radii,
        "Z MSM Start (radii)": [ z - Constants.DIPOLE_OFFSET_RADII for z in start_z_mso_radii ],

        "X MSM End (radii)": end_x_mso_radii,
        "Y MSM End (radii)": end_y_mso_radii,
        "Z MSM End (radii)": [ z - Constants.DIPOLE_OFFSET_RADII for z in end_z_mso_radii ],

        "X MSM Start (km)": start_x_mso_km,
        "Y MSM Start (km)": start_y_mso_km,
        "Z MSM Start (km)": [z - Constants.DIPOLE_OFFSET_RADII for z in start_z_mso_km],

        "X MSM End (km)": end_x_mso_km,
        "Y MSM End (km)": end_y_mso_km,
        "Z MSM End (km)": [z - Constants.DIPOLE_OFFSET_RADII for z in end_z_mso_km],
    }

    multi_index_columns = pd.MultiIndex.from_tuples(
        [
            ("Type", "", ""),
            ("Start", "Time", ""),
            
            ("Start", "MSO", "X (radii)"),
            ("Start", "MSO", "Y (radii)"),
            ("Start", "MSO", "Z (radii)"),

            ("Start", "MSO", "X (km)"),
            ("Start", "MSO", "Y (km)"),
            ("Start", "MSO", "Z (km)"),

            ("Start", "MSM", "X (radii)"),
            ("Start", "MSM", "Y (radii)"),
            ("Start", "MSM", "Z (radii)"),

            ("Start", "MSM", "X (km)"),
            ("Start", "MSM", "Y (km)"),
            ("Start", "MSM", "Z (km)"),

            ("End", "Time", ""),
            ("End", "MSO", "X (radii)"),
            ("End", "MSO", "Y (radii)"),
            ("End", "MSO", "Z (radii)"),

            ("End", "MSO", "X (km)"),
            ("End", "MSO", "Y (km)"),
            ("End", "MSO", "Z (km)"),

            ("End", "MSM", "X (radii)"),
            ("End", "MSM", "Y (radii)"),
            ("End", "MSM", "Z (radii)"),

            ("End", "MSM", "X (km)"),
            ("End", "MSM", "Y (km)"),
            ("End", "MSM", "Z (km)"),
        ]
    )

    multi_index_data = [
        list_data["Interval Type"],

        list_data["Interval Start"],
        list_data["X MSO Start (radii)"],
        list_data["Y MSO Start (radii)"],
        list_data["Z MSO Start (radii)"],

        list_data["X MSO Start (km)"],
        list_data["Y MSO Start (km)"],
        list_data["Z MSO Start (km)"],

        list_data["X MSM Start (radii)"],
        list_data["Y MSM Start (radii)"],
        list_data["Z MSM Start (radii)"],

        list_data["X MSM Start (km)"],
        list_data["Y MSM Start (km)"],
        list_data["Z MSM Start (km)"],

        list_data["Interval End"],
        list_data["X MSO End (radii)"],
        list_data["Y MSO End (radii)"],
        list_data["Z MSO End (radii)"],

        list_data["X MSO End (km)"],
        list_data["Y MSO End (km)"],
        list_data["Z MSO End (km)"],

        list_data["X MSM End (radii)"],
        list_data["Y MSM End (radii)"],
        list_data["Z MSM End (radii)"],

        list_data["X MSM End (km)"],
        list_data["Y MSM End (km)"],
        list_data["Z MSM End (km)"],
    ]

    # Create a pandas dataframe with this information
    df = pd.DataFrame(data=dict(zip(multi_index_columns, multi_index_data)))

    if include_data_gaps is False:
        df = df.loc[ df["Type"] != "DATA_GAP" ]


    return df
